import os
import json
import gzip
import streamlit as st

from engine_backend import load_json, grade_answer, grade_exam_retry


BUNDLE_PATH = "course_bundle.json"

st.set_page_config(page_title="Adaptive Learning Engine", layout="wide", page_icon="ğŸ§ ")

st.title("ğŸ§  Adaptive Learning Engine (Hebrew)")
st.caption("×§×•×¨×¡-××’× ×•×¡×˜×™: ×˜×•×¢×Ÿ Bundle ××•×›×Ÿ ×•××ª×§×Ÿ ×ª×©×•×‘×•×ª ×¢× ××©×•×‘, ×¦×™×•×Ÿ ×•×”×©×•×•××” ×œ×¤×ª×¨×•× ×•×ª ××•×¤×ª.")

# Health check (×›×“×™ ×©×œ× ×™×”×™×” â€œ×¢××•×“ ×¨×™×§â€ ×‘×œ×™ ×œ×”×‘×™×Ÿ)
st.write("âœ… streamlit_app.py × ×˜×¢×Ÿ")

with st.sidebar:
    st.subheader("×”×’×“×¨×•×ª")
    api_key = st.text_input("DASHSCOPE_API_KEY", type="password")
    if api_key:
        os.environ["DASHSCOPE_API_KEY"] = api_key

    st.divider()
    st.write("×§×•×‘×¥ Bundle:")
    st.code(BUNDLE_PATH)

@st.cache_resource
def load_bundle():
    return load_json(BUNDLE_PATH)

bundle = None
try:
    bundle = load_bundle()
except Exception as e:
    st.error(f"×œ× ×”×¦×œ×—×ª×™ ×œ×˜×¢×•×Ÿ {BUNDLE_PATH}: {e}")

if not bundle:
    st.info("×›×“×™ ×œ×™×™×¦×¨ Bundle:×¥: ×©×™× ×§×‘×¦×™ TXT ×‘×ª×™×§×™×•×ª knowledge/ ×•-style/ ×•××– ×”×¨×¥ ingest_course_onefile.py")
    st.stop()

profile = bundle["adaptive_learning_engine_bundle"]["instances"]["active_course_profile"]
meta = profile.get("meta", {}) or {}
st.success(f"×§×•×¨×¡ × ×˜×¢×Ÿ: {meta.get('course_id', 'unknown')} | × ×•×¦×¨ ×‘×ª××¨×™×š: {meta.get('generated_at', 'unknown')}")

tabs = st.tabs(["âœï¸ Coach", "ğŸ§ª Exam Retry", "ğŸ§© Debug (×¤×¨×•×¤×™×œ)"])

with tabs[0]:
    st.subheader("âœï¸ ××¦×‘ Coach")
    col1, col2 = st.columns([1, 1])

    with col1:
        q = st.text_input("×©××œ×” / × ×•×©× (×œ× ×—×•×‘×”)", key="coach_q")
        a = st.text_area("×”×ª×©×•×‘×” ×©×œ×š", height=280, key="coach_a")
        mode = st.selectbox("××¦×‘ ×‘×“×™×§×”", ["coach", "examiner"], index=0)
        run = st.button("×‘×“×•×§", type="primary", use_container_width=True)

    with col2:
        if run:
            if not os.getenv("DASHSCOPE_API_KEY"):
                st.error("×—×¡×¨ DASHSCOPE_API_KEY (×©×™× ×‘×¡×™×™×“×‘×¨).")
            elif not a.strip():
                st.error("×—×¡×¨×” ×ª×©×•×‘×”.")
            else:
                with st.spinner("×‘×•×“×§×ª..."):
                    try:
                        res = grade_answer(bundle, student_answer=a, question_text=q, mode=mode)
                        st.session_state.coach_res = res
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×–××Ÿ ×‘×“×™×§×”: {e}")

        res = st.session_state.get("coach_res")
        if res:
            score = (res.get("score", {}) or {}).get("total", 0)
            st.metric("×¦×™×•×Ÿ", score)

            st.markdown("### ğŸ› ï¸ ××‘×—×•× ×™× (Diagnostics)")
            for i, d in enumerate(res.get("diagnostics", []) or [], start=1):
                title = f"{i}. {d.get('error_type')} | {d.get('severity')} | {d.get('category')}"
                with st.expander(title):
                    st.write("**××” ×”×‘×¢×™×”:**")
                    st.write(d.get("why_wrong"))
                    st.write("**××” × ×›×•×Ÿ / ×¤×ª×¨×•×Ÿ:**")
                    st.info((d.get("fix", {}) or {}).get("rewrite_suggestion", ""))
                    ev = d.get("evidence") or []
                    if ev:
                        st.caption(f"ğŸ“Œ ××§×•×¨: [{ev[0].get('doc_id')}] ×¢××•×“ {ev[0].get('page')}: {ev[0].get('quote')}")

            sp = res.get("sharpening_paragraph") or {}
            if sp.get("explanation"):
                st.markdown("### ğŸ¯ ×¤×¡×§×ª ×—×™×“×•×“")
                st.write(f"**{sp.get('title','× ×§×•×“×ª ×—×™×“×•×“')}**")
                st.write(sp.get("explanation"))
                if sp.get("memory_hook"):
                    st.caption(f"Hook: {sp.get('memory_hook')}")
                if sp.get("one_check_question"):
                    st.warning(f"×©××œ×ª ×‘×“×™×§×”: {sp.get('one_check_question')}")

            improved = (res.get("improved_answer") or {}).get("full_text")
            if improved:
                st.markdown("### âœ… ×ª×©×•×‘×” ××©×•×“×¨×’×ª")
                st.text_area("×’×¨×¡×” ××©×•×¤×¨×ª", improved, height=280)

with tabs[1]:
    st.subheader("ğŸ§ª Exam Retry (×”×©×•×•××” ×œ×¤×ª×¨×•×Ÿ ××•×¤×ª)")
    q2 = st.text_input("×©××œ×” / ×¨××– ×œ×–×™×”×•×™", key="retry_q")
    a2 = st.text_area("×”×ª×©×•×‘×” ×©×œ×š", height=260, key="retry_a")
    run2 = st.button("×”×©×•×•×” ×œ×¤×ª×¨×•×Ÿ ××•×¤×ª", type="primary", use_container_width=True)

    if run2:
        if not os.getenv("DASHSCOPE_API_KEY"):
            st.error("×—×¡×¨ DASHSCOPE_API_KEY (×©×™× ×‘×¡×™×™×“×‘×¨).")
        elif not a2.strip():
            st.error("×—×¡×¨×” ×ª×©×•×‘×”.")
        else:
            with st.spinner("××©×•×•×”..."):
                try:
                    res2 = grade_exam_retry(bundle, student_answer=a2, question_text=q2)
                    st.session_state.retry_res = res2
                except Exception as e:
                    st.error(f"×©×’×™××” ×‘×–××Ÿ ×”×©×•×•××”: {e}")

    res2 = st.session_state.get("retry_res")
    if res2:
        score = (res2.get("score", {}) or {}).get("total", 0)
        comp = res2.get("comparison_to_solution") or {}

        st.metric("×¦×™×•×Ÿ", score)
        st.write(f"**Matched Solution:** {comp.get('solution_id','(×œ× × ××¦×)')}")
        st.write(f"**Coverage:** {comp.get('coverage_score','?')}")

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("### ×—×¡×¨ ××•×œ ×¤×ª×¨×•×Ÿ")
            for p in comp.get("missing_points") or []:
                st.write(f"â€¢ {p}")
        with c2:
            st.markdown("### ×ª×•×¡×¤×•×ª ×˜×•×‘×•×ª")
            for p in comp.get("extra_points") or []:
                st.write(f"â€¢ {p}")

        if comp.get("style_gap_notes"):
            st.markdown("### ×¤×¢×¨×™ ×¡×’× ×•×Ÿ")
            for n in comp.get("style_gap_notes") or []:
                st.write(f"â€¢ {n}")

        st.markdown("### ××‘×—×•× ×™×")
        for i, d in enumerate(res2.get("diagnostics", []) or [], start=1):
            title = f"{i}. {d.get('error_type')} | {d.get('severity')} | {d.get('category')}"
            with st.expander(title):
                st.write(d.get("why_wrong"))
                st.info((d.get("fix", {}) or {}).get("rewrite_suggestion", ""))
                ev = d.get("evidence") or []
                if ev:
                    st.caption(f"ğŸ“Œ ××§×•×¨: [{ev[0].get('doc_id')}] ×¢××•×“ {ev[0].get('page')}: {ev[0].get('quote')}")

with tabs[2]:
    st.subheader("ğŸ§© Debug: Course Profile")
    st.json({
        "meta": profile.get("meta"),
        "docs": profile.get("doc_registry", [])[:8],
        "terms_count": len((profile.get("terminology", {}) or {}).get("canonical_terms", []) or []),
        "solutions_count": len((((profile.get("style_brain", {}) or {}).get("solutions_bank", {}) or {}).get("solutions", []) or [])),
        "has_raw_texts": bool((profile.get("raw_materials", {}) or {}).get("doc_text_by_id")),
    }, expanded=True)

    with st.expander("Show first 3 terms"):
        terms = (profile.get("terminology", {}) or {}).get("canonical_terms", []) or []
        st.json(terms[:3])

    with st.expander("Show first 2 solutions labels"):
        sols = (((profile.get("style_brain", {}) or {}).get("solutions_bank", {}) or {}).get("solutions", []) or []
        st.json([{"solution_id": s.get("solution_id"), "label": s.get("label")} for s in sols[:2]])
